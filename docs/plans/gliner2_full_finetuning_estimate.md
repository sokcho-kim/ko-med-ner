# GLiNER2 풀 파인튜닝 견적 산정

> 작성일: 2026-01-06

---

## 1. 배경

LoRA 파인튜닝 테스트 결과, 인코더 자체가 한국어를 처리하지 못해 성능 개선 실패.
→ **인코더 교체 + 풀 파인튜닝** 필요

---

## 2. 아키텍처 옵션

### Option A: 인코더만 교체
기존 GLiNER2 구조 유지, 인코더만 한국어용으로 교체

| 인코더 후보 | 파라미터 | 특징 |
|------------|----------|------|
| `klue/roberta-base` | 111M | KLUE 벤치마크 1위, 범용 |
| `monologg/koelectra-base-v3` | 110M | 한국어 특화, 경량 |
| `beomi/kcbert-base` | 110M | 한국어 댓글 학습 |
| `xlm-roberta-base` | 270M | 다국어, 검증됨 |

**권장**: `klue/roberta-base` (범용성 + 성능)

### Option B: GLiNER 구조 자체 수정
- GLiNER v2.1 코드베이스 기반
- 스키마 인터페이스 직접 구현

**단점**: 개발 공수 큼

---

## 3. 데이터 요구사항

### 3.1 데이터량 추정

| 규모 | 샘플 수 | 예상 F1 | 비고 |
|------|---------|---------|------|
| 최소 | 1,000개 | 60-70% | 기본 동작 |
| 권장 | 5,000개 | 75-85% | 실용 수준 |
| 이상적 | 10,000개+ | 85-90%+ | 프로덕션 수준 |

### 3.2 데이터 소스

| 소스 | 규모 | 품질 | 비용 |
|------|------|------|------|
| KBMC (HuggingFace) | 6,150개 | 골든 | 무료 |
| 대한민국 약전 (자체) | ~4,700페이지 | 실버 (생성 필요) | 무료 |
| GPT-4 실버셋 생성 | 무제한 | 실버 | API 비용 |
| 전문가 라벨링 | - | 골든 | 인건비 |

### 3.3 데이터 구축 비용

#### GPT-4 실버셋 생성 시
```
- 1개 샘플 생성: ~500 토큰 (input + output)
- 5,000개 × 500 토큰 = 2,500,000 토큰
- GPT-4o 비용: $2.50/1M input + $10/1M output
- 예상 비용: ~$15-25
```

#### 전문가 라벨링 시
```
- 1개 샘플 라벨링: 약 2-3분
- 5,000개 × 2.5분 = 12,500분 ≈ 208시간
- 시급 2만원 기준: ~420만원
```

---

## 4. 컴퓨팅 리소스

### 4.1 하드웨어 요구사항

| 구성 | GPU | VRAM | 용도 |
|------|-----|------|------|
| 최소 | T4 | 16GB | 소규모 실험 |
| 권장 | A10G | 24GB | 본격 학습 |
| 이상적 | A100 | 40GB+ | 대규모/빠른 학습 |

### 4.2 학습 시간 추정

**기준**: 5,000개 데이터, batch=16, 20 epochs

| GPU | 시간/epoch | 총 시간 |
|-----|-----------|---------|
| T4 (16GB) | ~15분 | ~5시간 |
| A10G (24GB) | ~8분 | ~2.5시간 |
| A100 (40GB) | ~3분 | ~1시간 |

### 4.3 클라우드 비용

#### AWS
| 인스턴스 | GPU | 시간당 비용 | 5시간 비용 |
|----------|-----|------------|-----------|
| g4dn.xlarge | T4 | $0.526 | $2.63 |
| g5.xlarge | A10G | $1.006 | $5.03 |
| p4d.24xlarge | A100 | $32.77 | $163.85 |

#### Vast.ai (저렴한 대안)
| GPU | 시간당 비용 | 5시간 비용 |
|-----|------------|-----------|
| RTX 3090 | ~$0.30 | ~$1.50 |
| A10 | ~$0.50 | ~$2.50 |
| A100 | ~$1.50 | ~$7.50 |

#### Lambda Labs
| GPU | 시간당 비용 | 5시간 비용 |
|-----|------------|-----------|
| A10 | $0.60 | $3.00 |
| A100 (40GB) | $1.10 | $5.50 |

---

## 5. 총 비용 견적

### Scenario A: 최소 비용 (MVP)
| 항목 | 비용 |
|------|------|
| 데이터 | KBMC 무료 (6,150개) |
| GPU | Vast.ai RTX 3090 × 5시간 = $1.50 |
| **총계** | **~$2 (약 3,000원)** |

### Scenario B: 권장 (실용 수준)
| 항목 | 비용 |
|------|------|
| 데이터 | KBMC + GPT-4 실버셋 5,000개 = ~$20 |
| GPU | Lambda A10 × 10시간 = $6 |
| 반복 실험 | ×3 = $18 |
| **총계** | **~$44 (약 6만원)** |

### Scenario C: 프로덕션 수준
| 항목 | 비용 |
|------|------|
| 데이터 | 전문가 라벨링 10,000개 = ~500만원 |
| GPU | A100 × 50시간 = ~$80 |
| 하이퍼파라미터 튜닝 | ×10 = $800 |
| **총계** | **~$900 + 라벨링비 (약 600만원)** |

---

## 6. 일정 추정

### 최소 MVP (1주)
| 단계 | 기간 | 산출물 |
|------|------|--------|
| 데이터 준비 | 1일 | KBMC 변환 완료 |
| 인코더 교체 | 1일 | 코드 수정 |
| 학습 | 1일 | 모델 체크포인트 |
| 평가 | 1일 | 성능 리포트 |
| 버퍼 | 3일 | 디버깅/반복 |

### 권장 (2-3주)
| 단계 | 기간 | 산출물 |
|------|------|--------|
| 데이터 구축 | 1주 | 실버셋 5,000개 |
| 모델 개발 | 3일 | 인코더 교체 완료 |
| 학습/튜닝 | 1주 | 최적 모델 |
| 평가/문서화 | 3일 | 최종 리포트 |

---

## 7. 리스크

| 리스크 | 확률 | 영향 | 대응 |
|--------|------|------|------|
| 인코더 호환성 문제 | 중 | 높음 | 사전 PoC 진행 |
| 성능 목표 미달 | 중 | 중 | 데이터 확대, 앙상블 |
| GPU 가용성 | 낮음 | 중 | 여러 클라우드 옵션 |
| 데이터 품질 이슈 | 중 | 높음 | 검증 파이프라인 |

---

## 8. 권장 사항

### 단기 (1주)
1. **KBMC 전체 데이터**로 인코더 교체 PoC 진행
2. `klue/roberta-base` 우선 테스트
3. Vast.ai 또는 Lambda Labs 사용 (비용 최소화)

### 중기 (1개월)
1. GPT-4로 실버셋 5,000개 추가 생성
2. 하이퍼파라미터 최적화
3. 목표 F1 80% 달성

### 장기 (3개월+)
1. 전문가 라벨링 데이터 확보
2. 도메인별 어댑터 (의약품, 질병, 시술 등)
3. 프로덕션 배포

---

## 9. 결론

| 항목 | 최소 | 권장 | 이상적 |
|------|------|------|--------|
| 데이터 | 6,150개 | 11,000개 | 20,000개+ |
| 비용 | 3,000원 | 6만원 | 600만원+ |
| 기간 | 1주 | 3주 | 3개월 |
| 예상 F1 | 65-75% | 80-85% | 90%+ |

**1차 권장**: Scenario B (권장 수준)로 시작
- 비용 대비 효과 최적
- 실패 시 손실 최소화
- 성공 시 Scenario C로 확장
